{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/yixiong_ren/work/FBM\n",
      "/home/yixiong_ren/work/FBM/result/analyse_SIL/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "local_path = os.getcwd()\n",
    "# 设置工作目录为项目的主目录\n",
    "os.chdir(os.path.join(local_path, \"../../\"))  # 使用相对路径将工作目录切换到 project 文件夹\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "project_path = os.path.abspath(os.path.join(local_path, \"../../\"))\n",
    "sys.path.append(project_path)   #将模块查找路径切换\n",
    "\n",
    "save_path = os.path.join(project_path, \"result/analyse_SIL/\")\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 使用示例\n",
    "utils.set_seed(42)  # 42 是一个示例种子数，您可以根据需求更改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = utils.get_dataloader(\"MNIST\", batch_size=batch_size, train=True, class_counts=[100]*10)\n",
    "test_loader = utils.get_dataloader(\"MNIST\", batch_size=batch_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 DataLoader 中的全部数据\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "for batch_data, batch_labels in train_loader:\n",
    "    train_features.append(batch_data.view(-1, 784))\n",
    "    train_labels.append(batch_labels)\n",
    "\n",
    "# 合并所有批次\n",
    "train_features = torch.cat(train_features, dim=0)\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "# 获取 DataLoader 中的全部数据\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for batch_data, batch_labels in train_loader:\n",
    "    test_features.append(batch_data.view(-1, 784))\n",
    "    test_labels.append(batch_labels)\n",
    "\n",
    "# 合并所有批次\n",
    "test_features = torch.cat(test_features, dim=0)\n",
    "test_labels = torch.cat(test_labels, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 可视化函数：将数据降维到 2D 并可视化\n",
    "def visualize_2d(features, labels, savepath=None):\n",
    "    \"\"\"\n",
    "    使用 t-SNE 将高维数据降维到 2D 并可视化。\n",
    "    :param features: 高维特征数据 (tensor or numpy array)\n",
    "    :param labels: 标签 (tensor or numpy array)\n",
    "    \"\"\"\n",
    "    # 转换为 numpy\n",
    "    features_np = features.detach().numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "    # 使用 t-SNE 降维到 2D\n",
    "    _, dims =features.shape\n",
    "    \n",
    "    if dims > 2:\n",
    "        #tsne = TSNE(n_components=2, random_state=42, perplexity=40)\n",
    "        pca = PCA(n_components=2)\n",
    "        features_2d = pca.fit_transform(features_np)\n",
    "        explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    else:\n",
    "        features_2d = features_np\n",
    "        explained_variance_ratio = None\n",
    "\n",
    "    # 绘制 2D 散点图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for label in np.unique(labels):\n",
    "        mask = labels_np == label\n",
    "        plt.scatter(\n",
    "            features_2d[mask, 0],\n",
    "            features_2d[mask, 1],\n",
    "            label=f\"Class {label}\",\n",
    "            alpha=0.6\n",
    "        )\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.title(\"Visualization of High-Dimensional Data\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 显示 PCA 信息占比\n",
    "    if explained_variance_ratio is not None:\n",
    "        info_text = f\"Explained Variance:\\nDim 1: {explained_variance_ratio[0]:.2%}\\nDim 2: {explained_variance_ratio[1]:.2%}\"\n",
    "        plt.text(0.05, 0.95, info_text, transform=plt.gca().transAxes, fontsize=10,\n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', alpha=0.2))\n",
    "\n",
    "    if savepath is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(savepath+'.png')\n",
    "    plt.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: -15.9489\n",
      "Epoch [2/100], Loss: -17.6740\n",
      "Epoch [3/100], Loss: -18.5091\n",
      "Epoch [4/100], Loss: -20.7987\n",
      "Epoch [5/100], Loss: -16.2474\n",
      "Epoch [6/100], Loss: -15.7654\n",
      "Epoch [7/100], Loss: -17.0134\n",
      "Epoch [8/100], Loss: -18.2751\n",
      "Epoch [9/100], Loss: -20.2878\n",
      "Epoch [10/100], Loss: -20.9477\n",
      "Epoch [11/100], Loss: -18.0155\n",
      "Epoch [12/100], Loss: -18.3732\n",
      "Epoch [13/100], Loss: -19.3668\n",
      "Epoch [14/100], Loss: -19.9940\n",
      "Epoch [15/100], Loss: -18.3440\n",
      "Epoch [16/100], Loss: -18.2764\n",
      "Epoch [17/100], Loss: -16.0233\n",
      "Epoch [18/100], Loss: -21.1292\n",
      "Epoch [19/100], Loss: -16.9698\n",
      "Epoch [20/100], Loss: -18.4256\n",
      "Epoch [21/100], Loss: -20.0123\n",
      "Epoch [22/100], Loss: -20.5775\n",
      "Epoch [23/100], Loss: -16.1305\n",
      "Epoch [24/100], Loss: -21.2787\n",
      "Epoch [25/100], Loss: -20.5678\n",
      "Epoch [26/100], Loss: -19.8668\n",
      "Epoch [27/100], Loss: -19.1025\n",
      "Epoch [28/100], Loss: -20.5015\n",
      "Epoch [29/100], Loss: -17.4643\n",
      "Epoch [30/100], Loss: -20.2660\n",
      "Epoch [31/100], Loss: -19.9885\n",
      "Epoch [32/100], Loss: -19.9500\n",
      "Epoch [33/100], Loss: -19.4660\n",
      "Epoch [34/100], Loss: -19.3659\n",
      "Epoch [35/100], Loss: -20.5069\n",
      "Epoch [36/100], Loss: -21.0749\n",
      "Epoch [37/100], Loss: -19.7004\n",
      "Epoch [38/100], Loss: -14.2807\n",
      "Epoch [39/100], Loss: -19.1102\n",
      "Epoch [40/100], Loss: -17.3172\n",
      "Epoch [41/100], Loss: -13.3738\n",
      "Epoch [42/100], Loss: -18.0304\n",
      "Epoch [43/100], Loss: -16.8928\n",
      "Epoch [44/100], Loss: 5.2670\n",
      "Epoch [45/100], Loss: -18.2024\n",
      "Epoch [46/100], Loss: -18.5559\n",
      "Epoch [47/100], Loss: -15.5864\n",
      "Epoch [48/100], Loss: -17.3513\n",
      "Epoch [49/100], Loss: -17.8700\n",
      "Epoch [50/100], Loss: -16.7718\n",
      "Epoch [51/100], Loss: -17.6430\n",
      "Epoch [52/100], Loss: -15.6058\n",
      "Epoch [53/100], Loss: -15.7860\n",
      "Epoch [54/100], Loss: -12.7158\n",
      "Epoch [55/100], Loss: -16.7297\n",
      "Epoch [56/100], Loss: -16.7641\n",
      "Epoch [57/100], Loss: -17.0760\n",
      "Epoch [58/100], Loss: -14.4782\n",
      "Epoch [59/100], Loss: -15.6873\n",
      "Epoch [60/100], Loss: -15.2656\n",
      "Epoch [61/100], Loss: -15.2679\n",
      "Epoch [62/100], Loss: 33.5967\n",
      "Epoch [63/100], Loss: -16.9138\n",
      "Epoch [64/100], Loss: -4.5078\n",
      "Epoch [65/100], Loss: -14.5776\n",
      "Epoch [66/100], Loss: -14.9887\n",
      "Epoch [67/100], Loss: -14.5254\n",
      "Epoch [68/100], Loss: 1016.8691\n",
      "Epoch [69/100], Loss: -14.5488\n",
      "Epoch [70/100], Loss: -13.2869\n",
      "Epoch [71/100], Loss: -14.8529\n",
      "Epoch [72/100], Loss: -13.0378\n",
      "Epoch [73/100], Loss: -8.8623\n",
      "Epoch [74/100], Loss: -11.3013\n",
      "Epoch [75/100], Loss: -12.2130\n",
      "Epoch [76/100], Loss: -12.0030\n",
      "Epoch [77/100], Loss: 1183.3499\n",
      "Epoch [78/100], Loss: -13.8312\n",
      "Epoch [79/100], Loss: -12.8873\n",
      "Epoch [80/100], Loss: -8.9914\n",
      "Epoch [81/100], Loss: -9.9836\n",
      "Epoch [82/100], Loss: -14.1339\n",
      "Epoch [83/100], Loss: -11.7482\n",
      "Epoch [84/100], Loss: -11.7450\n",
      "Epoch [85/100], Loss: -11.7106\n",
      "Epoch [86/100], Loss: 4.7335\n",
      "Epoch [87/100], Loss: -10.4363\n",
      "Epoch [88/100], Loss: -9.7229\n",
      "Epoch [89/100], Loss: -11.4893\n",
      "Epoch [90/100], Loss: -10.4321\n",
      "Epoch [91/100], Loss: -11.5880\n",
      "Epoch [92/100], Loss: -10.0710\n",
      "Epoch [93/100], Loss: -11.5546\n",
      "Epoch [94/100], Loss: -10.2093\n",
      "Epoch [95/100], Loss: -10.1488\n",
      "Epoch [96/100], Loss: -11.2388\n",
      "Epoch [97/100], Loss: -12.4970\n",
      "Epoch [98/100], Loss: -9.7686\n",
      "Epoch [99/100], Loss: -9.7799\n",
      "Epoch [100/100], Loss: -8.5656\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from loss.loss import FBMLoss\n",
    "from models.modelset import FBMLayer\n",
    "\n",
    "# 定义超参数\n",
    "input_size = 784\n",
    "hidden_dim = 1000\n",
    "num_classes = 10      # MNIST有10个类别\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "b = 1.5\n",
    "a = 2\n",
    "\n",
    "# 实例化模型、定义损失函数和优化器\n",
    "model = FBMLayer(input_size, hidden_dim).to(device)\n",
    "criterion = FBMLoss(hidden_dim, 0.01, a, b, losstype=\"fast_StrongInter\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # 将图像和标签移动到 GPU 上\n",
    "        images = images.view(-1, input_size).to(device)  # 展平图像并转移到 GPU\n",
    "        labels = labels.to(device)  # 标签移动到 GPU\n",
    "        #labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        #loss = criterion(outputs, labels_one_hot, model.linear.weight)\n",
    "        loss = criterion(outputs, labels, model.linear.weight)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    '''分析代码'''\n",
    "    with torch.no_grad():\n",
    "        local_data = train_features.view(-1, input_size).to(device)\n",
    "        analyse_data = model(local_data).cpu()\n",
    "        \n",
    "        local_save_path = os.path.join(save_path, f\"output_{a:.2f}_{b:.2f}/\")\n",
    "        os.makedirs(local_save_path, exist_ok=True)\n",
    "\n",
    "        visualize_2d(analyse_data, train_labels.cpu(), os.path.join(local_save_path, f\"{epoch}\"))   #画出最后的结果\n",
    "        out_dis = utils.fast_FBDistance(analyse_data, train_labels.cpu())\n",
    "        # 计算对角项的和\n",
    "        diagonal_sum = torch.diag(out_dis).sum()\n",
    "\n",
    "        # 计算非对角项的和\n",
    "        total_sum = out_dis.sum()\n",
    "        non_diagonal_sum = total_sum - diagonal_sum\n",
    "        with open(os.path.join(local_save_path, \"distance.txt\"), \"a\") as file:\n",
    "            file.write(\"=\"*20+\"\\n\"+f\"epoch={epoch}\"+\"\\n\")\n",
    "            file.write(str(out_dis) + \"\\n\")  # 写入数据并换行\n",
    "            file.write(f\"Bosen={diagonal_sum}\\t Fermi={non_diagonal_sum}\\n\")\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"写成可以搜索的形式\"\"\"\n",
    "def more_data(a, b):\n",
    "    # 定义超参数\n",
    "    input_size = dimensions\n",
    "    hidden_dim = 10\n",
    "    num_classes = 10      # MNIST有10个类别\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 100\n",
    "    batch_size = 64\n",
    "    #b = 1.5\n",
    "    #a = 2\n",
    "\n",
    "    # 实例化模型、定义损失函数和优化器\n",
    "    model = SingleLayerNN(input_size, hidden_dim).to(device)\n",
    "    criterion = FBMLoss(hidden_dim, 0.01, a, b)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            # 将图像和标签移动到 GPU 上\n",
    "            images = images.view(-1, input_size).to(device)  # 展平图像并转移到 GPU\n",
    "            labels = labels.to(device)  # 标签移动到 GPU\n",
    "            #labels_one_hot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            #loss = criterion(outputs, labels_one_hot, model.linear.weight)\n",
    "            loss = criterion(outputs, labels, model.linear.weight)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        '''分析代码'''\n",
    "        with torch.no_grad():\n",
    "            local_data = train_features.view(-1, input_size).to(device)\n",
    "            analyse_data = model(local_data).cpu()\n",
    "            \n",
    "            local_save_path = os.path.join(save_path, f\"train2/hidden{hidden_dim}_a{a:.2f}_b{b:.2f}/\")\n",
    "            os.makedirs(local_save_path, exist_ok=True)\n",
    "\n",
    "            visualize_2d(analyse_data, train_labels.cpu(), os.path.join(local_save_path, f\"{epoch}\"))   #画出最后的结果\n",
    "            out_dis = fast_FBDistance(analyse_data, train_labels.cpu())\n",
    "            # 计算对角项的和\n",
    "            diagonal_sum = torch.diag(out_dis).sum()\n",
    "\n",
    "            # 计算非对角项的和\n",
    "            total_sum = out_dis.sum()\n",
    "            non_diagonal_sum = total_sum - diagonal_sum\n",
    "            with open(os.path.join(local_save_path, \"distance.txt\"), \"a\") as file:\n",
    "                file.write(\"=\"*20+\"\\n\"+f\"epoch={epoch}\"+\"\\n\")\n",
    "                file.write(str(out_dis) + \"\\n\")  # 写入数据并换行\n",
    "                F_B = non_diagonal_sum/diagonal_sum\n",
    "                file.write(f\"Bosen={diagonal_sum:.4f}\\t Fermi={non_diagonal_sum:.4f}\\t Fermi_Bosen={F_B:.4f}\\n\")\n",
    "        \n",
    "        #print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "for a in np.linspace(0.3, 2, 10):\n",
    "    for b in np.linspace(0.3, 2, 10):\n",
    "        more_data(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制在测试集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out_features = model(test_features.to(device)).cpu()\n",
    "visualize_2d(out_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
